{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "#from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from dotenv import load_dotenv\n",
    "import pandas_ta as ta\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set API keys\n",
    "#ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "FRED_API_KEY = os.getenv('FRED_API_KEY')\n",
    "\n",
    "#if not ALPHA_VANTAGE_API_KEY:\n",
    "#    raise ValueError(\"Set Alpha Vantage API key in the '.env' file.\")\n",
    "if not FRED_API_KEY:\n",
    "    raise ValueError(\"Set FRED API key in the '.env' file.\")\n",
    "\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "#alpha_fd = FundamentalData(key=ALPHA_VANTAGE_API_KEY, output_format='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2017-01-01'\n",
    "END_DATE = '2023-12-31'\n",
    "\n",
    "\n",
    "COMPANIES = {\n",
    "    'Telus': ['T.TO', 'TU'],\n",
    "    'Rogers Communications': ['RCI-B.TO', 'RCI'],\n",
    "    'Quebecor': ['QBR-B.TO'],\n",
    "    'Cogeco Communications': ['CCA.TO'],\n",
    "    'Bell Canada (BCE Inc.)': ['BCE.TO', 'BCE'],\n",
    "    'Hydro One': ['H.TO'],\n",
    "    'Fortis': ['FTS.TO', 'FTS'],\n",
    "    'AltaGas': ['ALA.TO'],\n",
    "    'Canadian National Railway': ['CNR.TO', 'CNI'],\n",
    "    'Canadian Pacific Railway': ['CP.TO', 'CP'],\n",
    "    'Metro': ['MRU.TO'],\n",
    "    'Loblaws': ['L.TO'],\n",
    "    'Empire': ['EMP-A.TO'],\n",
    "    'Alimentation Couche-Tard': ['ATD-B.TO', 'ATD'],\n",
    "}\n",
    "\n",
    "\n",
    "MACRO_INDICATORS = {\n",
    "    'GDP': {'series_id': 'GDP', 'frequency': 'Quarterly'},\n",
    "    'CPI': {'series_id': 'CPIAUCSL', 'frequency': 'Monthly'},\n",
    "    'Unemployment Rate': {'series_id': 'UNRATE', 'frequency': 'Monthly'},\n",
    "    'Interest Rate': {'series_id': 'FEDFUNDS', 'frequency': 'Monthly'},\n",
    "    'Industrial Production': {'series_id': 'INDPRO', 'frequency': 'Monthly'},\n",
    "    'Consumer Confidence': {'series_id': 'UMCSENT', 'frequency': 'Monthly'},\n",
    "    'Retail Sales': {'series_id': 'RSAFS', 'frequency': 'Monthly'},\n",
    "    'Housing Starts': {'series_id': 'HOUST', 'frequency': 'Monthly'},\n",
    "    'Durable Goods Orders': {'series_id': 'DGORDER', 'frequency': 'Monthly'},\n",
    "    'Producer Price Index': {'series_id': 'PPIACO', 'frequency': 'Monthly'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fetch_data_with_retry(fetch_function, *args, max_retries=3, sleep_time=15, **kwargs):\n",
    "#    for attempt in range(max_retries):\n",
    "#        try:\n",
    "#            return fetch_function(*args, **kwargs)\n",
    "#        except Exception as e:\n",
    "#            print(f\"Error: {e}. Retrying in {sleep_time} seconds...\")\n",
    "#            time.sleep(sleep_time)\n",
    "#    print(\"Max retries exceeded.\")\n",
    "#    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technical_data(companies, start_date, end_date):\n",
    "    technical_data_list = []\n",
    "    for company, tickers in companies.items():\n",
    "        data_fetched = False\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                data = yf.download(ticker, start=start_date, end=end_date)\n",
    "                if data.empty:\n",
    "                    continue\n",
    "                data.reset_index(inplace=True)\n",
    "                data.columns = data.columns.get_level_values(0)\n",
    "                # Calculate returns\n",
    "                data['Daily Return'] = data['Close'].pct_change()\n",
    "                data['Adjusted Daily Return'] = data['Adj Close'].pct_change()\n",
    "                # Add company and ticker info\n",
    "                data['Company'] = company\n",
    "                data['Ticker'] = ticker\n",
    "                # Calculate technical indicators\n",
    "                data = calculate_technical_indicators(data)\n",
    "                technical_data_list.append(data)\n",
    "                print(f\"Technical data fetched for {company} ({ticker})\")\n",
    "                data_fetched = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching technical data for {company} ({ticker}): {e}\")\n",
    "        if not data_fetched:\n",
    "            print(f\"Failed to fetch technical data for {company}\")\n",
    "    # Combine all data into one DataFrame\n",
    "    technical_data = pd.concat(technical_data_list, ignore_index=True)\n",
    "    return technical_data\n",
    "\n",
    "def calculate_technical_indicators(data):\n",
    "    # Moving Averages\n",
    "    data['SMA_20'] = ta.sma(data['Close'], length=20)\n",
    "    data['EMA_20'] = ta.ema(data['Close'], length=20)\n",
    "    # Bollinger Bands\n",
    "    bbands = ta.bbands(data['Close'], length=20)\n",
    "    data = pd.concat([data, bbands], axis=1)\n",
    "    # Relative Strength Index\n",
    "    data['RSI_14'] = ta.rsi(data['Close'], length=14)\n",
    "    # Moving Average Convergence Divergence\n",
    "    macd = ta.macd(data['Close'])\n",
    "    data = pd.concat([data, macd], axis=1)\n",
    "    return data\n",
    "\n",
    "def melt_technical_data(data):\n",
    "    \"\"\"\n",
    "    Melt the technical data DataFrame into long format.\n",
    "    \"\"\"\n",
    "    id_vars = ['Company', 'Ticker', 'Date']\n",
    "    value_vars = [col for col in data.columns if col not in id_vars]\n",
    "    melted_data = data.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name='Variable',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    return melted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_data = get_technical_data(COMPANIES, START_DATE, END_DATE)\n",
    "technical_data['Date'] = pd.to_datetime(technical_data['Date']).dt.date\n",
    "technical_data = technical_data[technical_data['Date'] >= pd.to_datetime('2018-01-01').date()]\n",
    "technical_melted = melt_technical_data(technical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macro_data(indicators, start_date, end_date):\n",
    "    macro_data_list = []\n",
    "    for indicator_name, info in indicators.items():\n",
    "        series_id = info['series_id']\n",
    "        frequency = info['frequency']\n",
    "        try:\n",
    "            data = fred.get_series(series_id, observation_start=start_date, observation_end=end_date)\n",
    "            data = data.to_frame(name='Value')\n",
    "            data['Indicator'] = indicator_name\n",
    "            data['Frequency'] = frequency\n",
    "            data.index.rename('Date', inplace=True)\n",
    "            data.reset_index(inplace=True)\n",
    "\n",
    "            # Calculate one-period percentage change\n",
    "            data['Percent_Change'] = data['Value'].pct_change()\n",
    "\n",
    "            # Create a separate DataFrame for the percentage change\n",
    "            percent_change_data = data[['Date', 'Percent_Change', 'Indicator', 'Frequency']].copy()\n",
    "            percent_change_data.rename(columns={'Percent_Change': 'Value'}, inplace=True)\n",
    "            percent_change_data['Indicator'] = percent_change_data['Indicator'] + \" Pct Change\"\n",
    "\n",
    "            macro_data_list.append(data)\n",
    "            macro_data_list.append(percent_change_data)\n",
    "            \n",
    "            print(f\"Macro data fetched for {indicator_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching macro data for {indicator_name} ({series_id}): {e}\")\n",
    "\n",
    "    # Combine all data into one DataFrame\n",
    "    macro_data = pd.concat(macro_data_list, ignore_index=True)\n",
    "    macro_data = macro_data.drop([\"Percent_Change\"], axis=1)\n",
    "    return macro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data = get_macro_data(MACRO_INDICATORS, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the outputs as pickle files\n",
    "#with open('macro_data.pkl', 'wb') as macro_file:\n",
    "#    pickle.dump(macro_data, macro_file)\n",
    "\n",
    "#with open('technical_data.pkl', 'wb') as technical_file:\n",
    "#    pickle.dump(technical_data, technical_file)\n",
    "\n",
    "#with open('technical_melted.pkl', 'wb') as melted_file:\n",
    "#    pickle.dump(technical_melted, melted_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
