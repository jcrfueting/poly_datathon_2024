{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import uuid\n",
    "\n",
    "import tomllib\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the directory\n",
    "directory_path = '../data/docs'\n",
    "\n",
    "# Find all PDF files recursively\n",
    "pdf_files = glob.glob(os.path.join(directory_path, '**', '*.pdf'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(conversation, client, model_id):\n",
    "    try:\n",
    "        # Send the message to the model, using a basic inference configuration\n",
    "        response = client.converse(\n",
    "                    modelId=model_id,\n",
    "                    messages=conversation,\n",
    "                    inferenceConfig={\"maxTokens\": 200, \"temperature\": 1},\n",
    "                    additionalModelRequestFields={\"top_k\": 250, \"top_p\": 1},\n",
    "        )\n",
    "\n",
    "        # Extract and print the response text\n",
    "        return response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        #print(response_text)\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def extract_name_year(splits, client, model_id, n_page = 3):\n",
    "\n",
    "    doc_identifier = [*splits[:n_page], *splits[-n_page:]]\n",
    "    doc_identifier = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in doc_identifier])\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "\n",
    "    Question : What is the name of the company, what financial year this report is about?\n",
    "\n",
    "    Output : only json string format with two keys (company, year)\n",
    "\n",
    "    Error : if you could not find anything the values in json should be empty strings\n",
    "\n",
    "    Context : {doc_identifier}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    conversation = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": prompt_text}]  # Wrap the prompt in a list of dictionaries\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    response = query_llm(conversation, client, model_id)\n",
    "    return response\n",
    "\n",
    "def add_name_year_tags(split_documents, info_dict):\n",
    "    embedder = BedrockEmbeddings()\n",
    "    modified_docs = []\n",
    "\n",
    "    record_id = uuid.uuid4()\n",
    "\n",
    "    for doc in split_documents:\n",
    "        if info_dict['company'] and info_dict['year']:\n",
    "            modified_content = f\"\"\"\n",
    "                <company> {info_dict['company']} <company>\n",
    "                <year> {info_dict['year']} <year>\n",
    "\n",
    "                {doc.page_content}\n",
    "\n",
    "                <company> {info_dict['company']} <company>\n",
    "                <year> {info_dict['company']} <year>\n",
    "                \"\"\"\n",
    "        else:\n",
    "            modified_content = doc.page_content\n",
    "\n",
    "        modified_docs.append(dict(company = info_dict['company'], year = info_dict['year'], embedding = embedder.embed_query(modified_content), content = modified_content, record_id = record_id))\n",
    "\n",
    "    return modified_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f737f8fd91f14675b1c956b18ce2aa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = []\n",
    "for pdf_path in tqdm(pdf_files):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=5000)\n",
    "    split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    info_dict = extract_name_year(split_documents, client, model_id, n_page = 3)\n",
    "\n",
    "    info_dict = json.loads(info_dict)\n",
    "\n",
    "    docs.extend(add_name_year_tags(split_documents, info_dict))\n",
    "\n",
    "    with open(\"../data/database/db.pkl\", \"wb\") as file:\n",
    "        pickle.dump(docs, file = file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f666772f-f6cc-47eb-893b-c81375f50f0b'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
